{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extending Folio with Custom Models\n",
    "\n",
    "This notebook demonstrates how to extend Folio with custom surrogate models,\n",
    "acquisition functions, and recommenders. We cover two approaches:\n",
    "\n",
    "1. **Part 1: Inline implementation** - Self-contained in the notebook for rapid prototyping\n",
    "2. **Part 2: Modular approach** - Production-ready code in external modules\n",
    "\n",
    "**Target audience**: ML researchers and advanced users who want to plug in custom models.\n",
    "\n",
    "**Prerequisites**: Familiarity with PyTorch and basic Bayesian optimization concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from botorch.acquisition import AcquisitionFunction\n",
    "from botorch.models.model import Model\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "\n",
    "from folio.api import Folio\n",
    "from folio.core.config import TargetConfig\n",
    "from folio.core.schema import InputSpec, OutputSpec\n",
    "from folio.surrogates.base import Surrogate\n",
    "from folio.recommenders.base import Recommender\n",
    "from folio.recommenders.acquisitions.base import Acquisition\n",
    "from folio.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Test Function\n",
    "\n",
    "We'll use the same 2D quadratic function from earlier demos:\n",
    "- **Inputs**: `x1`, `x2` in [0, 10]\n",
    "- **Output**: yield = 100 - (x1 - 7)^2 - (x2 - 3)^2\n",
    "- **True optimum**: (7, 3) with yield = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_experiment(x1: float, x2: float) -> float:\n",
    "    \"\"\"Simulated experiment: 2D quadratic with optimum at (7, 3).\"\"\"\n",
    "    noise = np.random.normal(0, 0.5)\n",
    "    return 100 - (x1 - 7)**2 - (x2 - 3)**2 + noise\n",
    "\n",
    "TRUE_OPTIMUM = {\"x1\": 7.0, \"x2\": 3.0}\n",
    "TRUE_YIELD = 100.0\n",
    "BOUNDS = np.array([[0.0, 0.0], [10.0, 10.0]])  # shape (2, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Inline Implementation\n",
    "\n",
    "This section shows how to implement custom models directly in your notebook. Useful for:\n",
    "- Rapid prototyping\n",
    "- One-off experiments\n",
    "- Understanding the interfaces before creating reusable modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 1.1 Custom Surrogate: Neural Network Ensemble\n",
    "\n",
    "### Interface Requirements\n",
    "\n",
    "To create a custom surrogate, subclass `folio.surrogates.base.Surrogate` and implement:\n",
    "\n",
    "```python\n",
    "class Surrogate(ABC):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Sets self._is_fitted = False\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> \"Surrogate\":\n",
    "        \"\"\"\n",
    "        X: shape (n_samples, n_features), dtype float64\n",
    "        y: shape (n_samples,) or (n_samples, 1), dtype float64\n",
    "        Returns: self (for method chaining)\n",
    "        Must set: self._is_fitted = True\n",
    "        \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        X: shape (n_candidates, n_features)\n",
    "        Returns: (mean, std) both shape (n_candidates,)\n",
    "        Must raise: NotFittedError if not fitted\n",
    "        \"\"\"\n",
    "```\n",
    "\n",
    "### Implementation: NN Ensemble\n",
    "\n",
    "We'll create an ensemble of small MLPs. Uncertainty comes from prediction disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _MLP(nn.Module):\n",
    "    \"\"\"Simple 2-layer MLP for ensemble members.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 32):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class NNEnsembleSurrogate(Surrogate):\n",
    "    \"\"\"Neural network ensemble for uncertainty estimation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_members : int\n",
    "        Number of ensemble members.\n",
    "    hidden_dim : int\n",
    "        Hidden layer size for each MLP.\n",
    "    n_epochs : int\n",
    "        Training epochs per member.\n",
    "    lr : float\n",
    "        Learning rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_members: int = 5,\n",
    "        hidden_dim: int = 32,\n",
    "        n_epochs: int = 200,\n",
    "        lr: float = 0.01,\n",
    "    ):\n",
    "        # REQUIRED: call super().__init__() to set _is_fitted = False\n",
    "        super().__init__()\n",
    "        self.n_members = n_members\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self._members: list[_MLP] = []\n",
    "        self._y_mean = 0.0\n",
    "        self._y_std = 1.0\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> \"NNEnsembleSurrogate\":\n",
    "        \"\"\"Fit ensemble to training data.\"\"\"\n",
    "        input_dim = X.shape[1]\n",
    "        \n",
    "        X_t = torch.tensor(X, dtype=torch.float32)\n",
    "        y_t = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "        \n",
    "        # Normalize targets for stability\n",
    "        self._y_mean = float(y_t.mean())\n",
    "        self._y_std = float(y_t.std()) + 1e-6\n",
    "        y_norm = (y_t - self._y_mean) / self._y_std\n",
    "        \n",
    "        self._members = []\n",
    "        for i in range(self.n_members):\n",
    "            mlp = _MLP(input_dim, self.hidden_dim)\n",
    "            opt = torch.optim.Adam(mlp.parameters(), lr=self.lr)\n",
    "            loss_fn = nn.MSELoss()\n",
    "            \n",
    "            for _ in range(self.n_epochs):\n",
    "                opt.zero_grad()\n",
    "                loss = loss_fn(mlp(X_t), y_norm)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            \n",
    "            mlp.eval()\n",
    "            self._members.append(mlp)\n",
    "        \n",
    "        # REQUIRED: set _is_fitted = True\n",
    "        self._is_fitted = True\n",
    "        \n",
    "        # REQUIRED: return self for method chaining\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Predict mean and std from ensemble disagreement.\"\"\"\n",
    "        # REQUIRED: check fitted state\n",
    "        if not self._is_fitted:\n",
    "            raise NotFittedError(\"Call fit() before predict()\")\n",
    "        \n",
    "        X_t = torch.tensor(X, dtype=torch.float32)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = torch.stack([m(X_t) for m in self._members])\n",
    "        \n",
    "        # Shape: (n_members, n_candidates, 1) -> (n_members, n_candidates)\n",
    "        preds = preds.squeeze(-1)\n",
    "        \n",
    "        # Denormalize\n",
    "        preds = preds * self._y_std + self._y_mean\n",
    "        \n",
    "        mean = preds.mean(dim=0).numpy()\n",
    "        std = preds.std(dim=0).numpy()\n",
    "        std = np.maximum(std, 1e-6)  # Ensure non-zero\n",
    "        \n",
    "        return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Test the Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some training data\n",
    "np.random.seed(42)\n",
    "X_train = np.random.uniform(0, 10, size=(10, 2))\n",
    "y_train = np.array([synthetic_experiment(x[0], x[1]) for x in X_train])\n",
    "\n",
    "# Fit and predict\n",
    "surrogate = NNEnsembleSurrogate(n_members=5, n_epochs=100)\n",
    "surrogate.fit(X_train, y_train)\n",
    "\n",
    "# Test on new points\n",
    "X_test = np.array([[7.0, 3.0], [0.0, 0.0], [5.0, 5.0]])\n",
    "mean, std = surrogate.predict(X_test)\n",
    "\n",
    "print(\"Test predictions:\")\n",
    "for i, (x, m, s) in enumerate(zip(X_test, mean, std)):\n",
    "    print(f\"  x={x} -> mean={m:.2f}, std={s:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 1.2 Custom Recommender: Using NN Ensemble with Folio API\n",
    "\n",
    "### Interface Requirements\n",
    "\n",
    "To create a custom recommender that works with `folio.suggest()`, subclass\n",
    "`folio.recommenders.base.Recommender` and implement:\n",
    "\n",
    "```python\n",
    "class Recommender(ABC):\n",
    "    def __init__(self, project: Project):\n",
    "        self.project = project\n",
    "    \n",
    "    @abstractmethod\n",
    "    def recommend_from_data(\n",
    "        self,\n",
    "        X: np.ndarray,           # shape (n_samples, n_features)\n",
    "        y: np.ndarray,           # shape (n_samples, n_objectives)\n",
    "        bounds: np.ndarray,      # shape (2, n_features)\n",
    "        maximize: list[bool],    # one bool per objective\n",
    "    ) -> np.ndarray:             # shape (n_features,)\n",
    "        \"\"\"Return suggested next input values.\"\"\"\n",
    "```\n",
    "\n",
    "The base class provides:\n",
    "- `recommend(observations)` - High-level method that extracts data and calls `recommend_from_data`\n",
    "- `random_sample_from_bounds(bounds)` - Helper for random sampling\n",
    "\n",
    "### Implementation: NNEnsembleRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNEnsembleRecommender(Recommender):\n",
    "    \"\"\"Custom recommender using NN ensemble + UCB acquisition.\n",
    "    \n",
    "    This recommender can be used with Folio's high-level API by\n",
    "    injecting it into the recommender cache.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    project : Project\n",
    "        The project defining inputs, outputs, and targets.\n",
    "    n_members : int\n",
    "        Number of ensemble members.\n",
    "    n_initial : int\n",
    "        Number of random samples before using the model.\n",
    "    n_candidates : int\n",
    "        Number of random candidates to evaluate.\n",
    "    beta : float\n",
    "        UCB exploration parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        project,\n",
    "        n_members: int = 5,\n",
    "        n_initial: int = 3,\n",
    "        n_candidates: int = 100,\n",
    "        beta: float = 2.0,\n",
    "    ):\n",
    "        # REQUIRED: call super().__init__(project)\n",
    "        super().__init__(project)\n",
    "        self.n_members = n_members\n",
    "        self.n_initial = n_initial\n",
    "        self.n_candidates = n_candidates\n",
    "        self.beta = beta\n",
    "        self._surrogate = None\n",
    "    \n",
    "    @property\n",
    "    def surrogate(self):\n",
    "        \"\"\"Access the fitted surrogate (for inspection/visualization).\"\"\"\n",
    "        return self._surrogate\n",
    "    \n",
    "    def recommend_from_data(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        bounds: np.ndarray,\n",
    "        maximize: list[bool],\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Suggest next experiment using NN ensemble + UCB.\"\"\"\n",
    "        # Random sampling phase\n",
    "        if len(X) < self.n_initial:\n",
    "            self._surrogate = None\n",
    "            return self.random_sample_from_bounds(bounds)\n",
    "        \n",
    "        # Handle multi-output (use first objective for simplicity)\n",
    "        y_flat = y[:, 0] if y.ndim == 2 else y\n",
    "        \n",
    "        # Fit NN ensemble\n",
    "        self._surrogate = NNEnsembleSurrogate(\n",
    "            n_members=self.n_members,\n",
    "            n_epochs=200,\n",
    "        )\n",
    "        self._surrogate.fit(X, y_flat)\n",
    "        \n",
    "        # Generate random candidates\n",
    "        candidates = np.random.uniform(\n",
    "            bounds[0], bounds[1],\n",
    "            size=(self.n_candidates, X.shape[1])\n",
    "        )\n",
    "        \n",
    "        # Predict and compute UCB\n",
    "        mean, std = self._surrogate.predict(candidates)\n",
    "        \n",
    "        if maximize[0]:\n",
    "            ucb = mean + self.beta * std\n",
    "        else:\n",
    "            ucb = -mean + self.beta * std\n",
    "        \n",
    "        # Return best candidate\n",
    "        return candidates[np.argmax(ucb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Using Custom Recommender with Folio API\n",
    "\n",
    "To use a custom recommender with `folio.suggest()`, inject it into Folio's recommender cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Folio instance and project\n",
    "db_path = tempfile.mktemp(suffix=\".db\")\n",
    "folio = Folio(db_path=db_path)\n",
    "\n",
    "folio.create_project(\n",
    "    name=\"nn_ensemble_demo\",\n",
    "    inputs=[\n",
    "        InputSpec(\"x1\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "        InputSpec(\"x2\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "    ],\n",
    "    outputs=[OutputSpec(\"yield\")],\n",
    "    target_configs=[TargetConfig(objective=\"yield\", objective_mode=\"maximize\")],\n",
    ")\n",
    "\n",
    "# Inject custom recommender\n",
    "project = folio.get_project(\"nn_ensemble_demo\")\n",
    "folio._recommenders[\"nn_ensemble_demo\"] = NNEnsembleRecommender(\n",
    "    project,\n",
    "    n_members=5,\n",
    "    n_initial=3,\n",
    "    beta=2.0,\n",
    ")\n",
    "\n",
    "print(\"Custom recommender injected!\")\n",
    "print(f\"Recommender type: {type(folio._recommenders['nn_ensemble_demo']).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization loop using folio.suggest()\n",
    "np.random.seed(42)\n",
    "N_ITERATIONS = 10\n",
    "\n",
    "print(\"Optimization with custom NNEnsembleRecommender via Folio API:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(N_ITERATIONS):\n",
    "    # Get suggestion using Folio's high-level API\n",
    "    suggestion = folio.suggest(\"nn_ensemble_demo\")[0]\n",
    "    x1, x2 = suggestion[\"x1\"], suggestion[\"x2\"]\n",
    "    \n",
    "    # Run experiment\n",
    "    result = synthetic_experiment(x1, x2)\n",
    "    \n",
    "    # Record observation\n",
    "    folio.add_observation(\n",
    "        project_name=\"nn_ensemble_demo\",\n",
    "        inputs={\"x1\": x1, \"x2\": x2},\n",
    "        outputs={\"yield\": result},\n",
    "    )\n",
    "    \n",
    "    print(f\"Iter {i+1:2d}: x1={x1:.2f}, x2={x2:.2f} -> yield={result:.2f}\")\n",
    "\n",
    "# Check best result\n",
    "observations = folio.get_observations(\"nn_ensemble_demo\")\n",
    "yields = [obs.outputs[\"yield\"] for obs in observations]\n",
    "best_idx = np.argmax(yields)\n",
    "best_obs = observations[best_idx]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best result: yield={yields[best_idx]:.2f}\")\n",
    "print(f\"  at x1={best_obs.inputs['x1']:.2f}, x2={best_obs.inputs['x2']:.2f}\")\n",
    "print(f\"True optimum: yield={TRUE_YIELD:.2f} at x1={TRUE_OPTIMUM['x1']:.2f}, x2={TRUE_OPTIMUM['x2']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the fitted surrogate for inspection\n",
    "recommender = folio.get_recommender(\"nn_ensemble_demo\")\n",
    "if recommender.surrogate is not None:\n",
    "    print(\"Surrogate is fitted!\")\n",
    "    print(f\"  Ensemble members: {len(recommender.surrogate._members)}\")\n",
    "    \n",
    "    # Make predictions at the optimum\n",
    "    X_opt = np.array([[7.0, 3.0]])\n",
    "    mean, std = recommender.surrogate.predict(X_opt)\n",
    "    print(f\"  Prediction at optimum: mean={mean[0]:.2f}, std={std[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 1.3 Custom Acquisition: Probability of Improvement\n",
    "\n",
    "### Interface Requirements\n",
    "\n",
    "For acquisition functions that work with BoTorch models (e.g., GPs), you need **two classes**:\n",
    "\n",
    "1. **Builder** (subclass `folio.recommenders.acquisitions.base.Acquisition`):\n",
    "```python\n",
    "class Acquisition(ABC):\n",
    "    @abstractmethod\n",
    "    def build(self, model: Model, best_f: float, maximize: bool) -> AcquisitionFunction:\n",
    "        \"\"\"Return a BoTorch-compatible acquisition function.\"\"\"\n",
    "```\n",
    "\n",
    "2. **Inner Function** (subclass `botorch.acquisition.AcquisitionFunction`):\n",
    "```python\n",
    "class MyAcquisition(AcquisitionFunction):\n",
    "    def __init__(self, model: Model, ...):\n",
    "        super().__init__(model=model)  # REQUIRED\n",
    "        # Use self.register_buffer() for tensor parameters\n",
    "    \n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        # X shape: (batch, q, d)\n",
    "        # Returns: shape (batch,)\n",
    "```\n",
    "\n",
    "### Implementation: Probability of Improvement (PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _PIAcquisition(AcquisitionFunction):\n",
    "    \"\"\"Inner BoTorch-compatible PI acquisition function.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: Model, best_f: float, xi: float, maximize: bool):\n",
    "        super().__init__(model=model)\n",
    "        self.register_buffer(\"best_f\", torch.as_tensor(best_f))\n",
    "        self.register_buffer(\"xi\", torch.as_tensor(xi))\n",
    "        self.maximize = maximize\n",
    "    \n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        posterior = self.model.posterior(X)\n",
    "        mean = posterior.mean.squeeze(-1)\n",
    "        std = posterior.variance.sqrt().squeeze(-1)\n",
    "        \n",
    "        if self.maximize:\n",
    "            improvement = mean - self.best_f - self.xi\n",
    "        else:\n",
    "            improvement = self.best_f - mean - self.xi\n",
    "        \n",
    "        Z = improvement / (std + 1e-9)\n",
    "        norm = Normal(0, 1)\n",
    "        pi = norm.cdf(Z)\n",
    "        pi = torch.where(std > 1e-6, pi, torch.zeros_like(pi))\n",
    "        \n",
    "        return pi.sum(dim=-1)\n",
    "\n",
    "\n",
    "class ProbabilityOfImprovement(Acquisition):\n",
    "    \"\"\"PI acquisition function builder.\"\"\"\n",
    "    \n",
    "    def __init__(self, xi: float = 0.0):\n",
    "        if xi < 0:\n",
    "            raise ValueError(\"xi must be non-negative\")\n",
    "        self.xi = xi\n",
    "    \n",
    "    def build(self, model: Model, best_f: float, maximize: bool) -> AcquisitionFunction:\n",
    "        return _PIAcquisition(model, best_f, self.xi, maximize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Modular Approach\n",
    "\n",
    "For production use, put custom models in external modules:\n",
    "\n",
    "```\n",
    "demos/\n",
    "  extensions/\n",
    "    __init__.py\n",
    "    custom_models.py  <- Your custom classes\n",
    "```\n",
    "\n",
    "This approach is better when you want to:\n",
    "- Reuse models across notebooks\n",
    "- Write proper tests\n",
    "- Version control your implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 2.1 Importing from External Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add demos directory to path\n",
    "demos_dir = Path(\".\").resolve()\n",
    "if str(demos_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(demos_dir))\n",
    "\n",
    "# Import custom models\n",
    "from extensions.custom_models import (\n",
    "    NNEnsembleRecommender as ModularRecommender,\n",
    "    NNEnsembleSurrogate as ModularSurrogate,\n",
    "    ProbabilityOfImprovement as ModularPI,\n",
    ")\n",
    "\n",
    "print(\"Imported from extensions/custom_models.py:\")\n",
    "print(f\"  - NNEnsembleRecommender: {ModularRecommender}\")\n",
    "print(f\"  - NNEnsembleSurrogate: {ModularSurrogate}\")\n",
    "print(f\"  - ProbabilityOfImprovement: {ModularPI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 2.2 Complete Optimization with Imported Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new project\n",
    "folio.create_project(\n",
    "    name=\"modular_demo\",\n",
    "    inputs=[\n",
    "        InputSpec(\"x1\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "        InputSpec(\"x2\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "    ],\n",
    "    outputs=[OutputSpec(\"yield\")],\n",
    "    target_configs=[TargetConfig(objective=\"yield\", objective_mode=\"maximize\")],\n",
    ")\n",
    "\n",
    "# Inject modular recommender\n",
    "project = folio.get_project(\"modular_demo\")\n",
    "folio._recommenders[\"modular_demo\"] = ModularRecommender(\n",
    "    project,\n",
    "    n_members=5,\n",
    "    n_initial=3,\n",
    "    beta=2.0,\n",
    ")\n",
    "\n",
    "print(f\"Injected: {type(folio._recommenders['modular_demo']).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "np.random.seed(789)\n",
    "N_ITERATIONS = 10\n",
    "\n",
    "print(\"Optimization with imported NNEnsembleRecommender:\")\n",
    "for i in range(N_ITERATIONS):\n",
    "    suggestion = folio.suggest(\"modular_demo\")[0]\n",
    "    x1, x2 = suggestion[\"x1\"], suggestion[\"x2\"]\n",
    "    result = synthetic_experiment(x1, x2)\n",
    "    \n",
    "    folio.add_observation(\n",
    "        project_name=\"modular_demo\",\n",
    "        inputs={\"x1\": x1, \"x2\": x2},\n",
    "        outputs={\"yield\": result},\n",
    "    )\n",
    "    \n",
    "    print(f\"  Iter {i+1:2d}: x1={x1:.2f}, x2={x2:.2f} -> yield={result:.2f}\")\n",
    "\n",
    "observations = folio.get_observations(\"modular_demo\")\n",
    "yields = [obs.outputs[\"yield\"] for obs in observations]\n",
    "best_idx = np.argmax(yields)\n",
    "best_obs = observations[best_idx]\n",
    "print(f\"\\nBest: yield={yields[best_idx]:.2f} at ({best_obs.inputs['x1']:.2f}, {best_obs.inputs['x2']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Extension Points\n",
    "\n",
    "| Component | Interface | Use Case |\n",
    "|-----------|-----------|----------|\n",
    "| **Surrogate** | `fit()`, `predict()` | Custom uncertainty models (ensembles, BNNs) |\n",
    "| **Acquisition** | `build()` returning `AcquisitionFunction` | Custom acquisition functions for BoTorch models |\n",
    "| **Recommender** | `recommend_from_data()` | Complete custom optimization strategy |\n",
    "\n",
    "### Custom Recommender Template\n",
    "\n",
    "```python\n",
    "from folio.recommenders.base import Recommender\n",
    "\n",
    "class MyRecommender(Recommender):\n",
    "    def __init__(self, project, **kwargs):\n",
    "        super().__init__(project)  # REQUIRED\n",
    "        # Store parameters\n",
    "    \n",
    "    def recommend_from_data(\n",
    "        self,\n",
    "        X: np.ndarray,        # (n_samples, n_features)\n",
    "        y: np.ndarray,        # (n_samples, n_objectives)\n",
    "        bounds: np.ndarray,   # (2, n_features)\n",
    "        maximize: list[bool], # per-objective\n",
    "    ) -> np.ndarray:          # (n_features,)\n",
    "        # Your optimization logic here\n",
    "        return next_x\n",
    "\n",
    "# Usage with Folio\n",
    "project = folio.get_project(\"my_project\")\n",
    "folio._recommenders[\"my_project\"] = MyRecommender(project)\n",
    "suggestion = folio.suggest(\"my_project\")  # Uses your recommender!\n",
    "```\n",
    "\n",
    "### Key Points\n",
    "\n",
    "1. **Recommender** is the main extension point for using custom models with Folio's API\n",
    "2. **Inject** custom recommenders via `folio._recommenders[project_name] = ...`\n",
    "3. **Surrogate** and **Acquisition** are useful for BoTorch-based approaches\n",
    "4. Start **inline** for prototyping, move to **modules** for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "folio.delete_project(\"nn_ensemble_demo\")\n",
    "folio.delete_project(\"modular_demo\")\n",
    "print(\"Demo complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
