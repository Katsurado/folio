{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Folio Executors: Automated Experiment Loops\n",
    "\n",
    "This notebook demonstrates how to use **Executors** in Folio for automated\n",
    "closed-loop optimization. Executors bridge the gap between Folio's suggestions\n",
    "and actual experiment execution.\n",
    "\n",
    "We'll cover:\n",
    "1. What executors are and why they're useful\n",
    "2. Creating a custom executor for simulation\n",
    "3. Using `folio.execute()` for automated optimization loops\n",
    "4. Built-in executors: `HumanExecutor` and `ClaudeLightExecutor`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from folio.api import Folio\n",
    "from folio.core.config import TargetConfig\n",
    "from folio.core.schema import InputSpec, OutputSpec\n",
    "from folio.core.observation import Observation\n",
    "from folio.core.project import Project\n",
    "from folio.executors import Executor, HumanExecutor, ClaudeLightExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary database\n",
    "db_path = tempfile.mktemp(suffix=\".db\")\n",
    "folio = Folio(db_path=db_path)\n",
    "print(f\"Database: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## What is an Executor?\n",
    "\n",
    "An **Executor** is a class that takes suggested input values from Folio and\n",
    "returns an `Observation` with the measured outputs. This abstraction allows:\n",
    "\n",
    "- **Human-in-the-loop**: Prompt users to run experiments manually (`HumanExecutor`)\n",
    "- **Autonomous operation**: Call APIs or robots automatically (`ClaudeLightExecutor`)\n",
    "- **Simulation**: Test optimization strategies with synthetic functions\n",
    "\n",
    "The Executor interface is simple:\n",
    "```python\n",
    "class Executor(ABC):\n",
    "    def execute(self, suggestion: dict, project: Project) -> Observation:\n",
    "        \"\"\"Run experiment with given inputs, return observation.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Creating a Custom Executor\n",
    "\n",
    "Let's create a **SimulatorExecutor** that runs a synthetic function.\n",
    "This is useful for testing optimization strategies before deploying to real experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatorExecutor(Executor):\n",
    "    \"\"\"Executor that simulates experiments using a synthetic function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Function that takes **inputs and returns dict of outputs.\n",
    "    noise_std : float\n",
    "        Standard deviation of Gaussian noise to add to outputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, func, noise_std: float = 0.0):\n",
    "        self.func = func\n",
    "        self.noise_std = noise_std\n",
    "    \n",
    "    def _run(self, suggestion: dict, project: Project) -> Observation:\n",
    "        \"\"\"Run the synthetic function with given inputs.\"\"\"\n",
    "        # Call the synthetic function\n",
    "        outputs = self.func(**suggestion)\n",
    "        \n",
    "        # Add noise if specified\n",
    "        if self.noise_std > 0:\n",
    "            outputs = {\n",
    "                k: v + np.random.normal(0, self.noise_std)\n",
    "                for k, v in outputs.items()\n",
    "            }\n",
    "        \n",
    "        return Observation(\n",
    "            project_id=project.id,\n",
    "            inputs=suggestion,\n",
    "            inputs_suggested=suggestion,\n",
    "            outputs=outputs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Define a Synthetic Function\n",
    "\n",
    "We'll optimize a 2D quadratic with optimum at (7, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def branin_like(x1: float, x2: float) -> dict:\n",
    "    \"\"\"A modified Branin-like function with known optimum.\n",
    "    \n",
    "    Optimum at (7, 3) with value 100.\n",
    "    \"\"\"\n",
    "    value = 100 - (x1 - 7)**2 - (x2 - 3)**2\n",
    "    return {\"yield\": value}\n",
    "\n",
    "# True optimum for reference\n",
    "TRUE_OPTIMUM = {\"x1\": 7.0, \"x2\": 3.0}\n",
    "TRUE_YIELD = 100.0\n",
    "\n",
    "# Test the function\n",
    "print(f\"At optimum: {branin_like(**TRUE_OPTIMUM)}\")\n",
    "print(f\"At (0, 0): {branin_like(0, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Create Project and Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project\n",
    "folio.create_project(\n",
    "    name=\"executor_demo\",\n",
    "    inputs=[\n",
    "        InputSpec(\"x1\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "        InputSpec(\"x2\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "    ],\n",
    "    outputs=[OutputSpec(\"yield\")],\n",
    "    target_configs=[TargetConfig(objective=\"yield\", objective_mode=\"maximize\")],\n",
    ")\n",
    "\n",
    "# Create executor with slight noise\n",
    "executor = SimulatorExecutor(branin_like, noise_std=0.5)\n",
    "print(\"Project and executor created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Using `folio.execute()` for Automated Loops\n",
    "\n",
    "The `execute()` method automates the optimization loop:\n",
    "1. Get suggestion via `suggest()`\n",
    "2. Run experiment via `executor.execute()`\n",
    "3. Record observation in database\n",
    "4. Repeat for `n_iter` iterations\n",
    "\n",
    "This replaces the manual loop we saw in earlier demos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 15 iterations of automated optimization\n",
    "observations = folio.execute(\n",
    "    project_name=\"executor_demo\",\n",
    "    n_iter=15,\n",
    "    executor=executor,\n",
    ")\n",
    "\n",
    "print(f\"Completed {len(observations)} experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all observations\n",
    "all_obs = folio.get_observations(\"executor_demo\")\n",
    "yields = [obs.outputs[\"yield\"] for obs in all_obs]\n",
    "\n",
    "# Find best\n",
    "best_idx = np.argmax(yields)\n",
    "best_obs = all_obs[best_idx]\n",
    "\n",
    "print(f\"Best result: yield={yields[best_idx]:.2f}\")\n",
    "print(f\"  at x1={best_obs.inputs['x1']:.2f}, x2={best_obs.inputs['x2']:.2f}\")\n",
    "print(f\"\\nTrue optimum: yield={TRUE_YIELD} at x1={TRUE_OPTIMUM['x1']}, x2={TRUE_OPTIMUM['x2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization progress\n",
    "running_best = np.maximum.accumulate(yields)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Left: optimization progress\n",
    "ax1.plot(range(1, len(yields) + 1), running_best, \"b-o\", label=\"Best found\")\n",
    "ax1.axhline(TRUE_YIELD, color=\"r\", linestyle=\"--\", label=\"True optimum\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_ylabel(\"Yield\")\n",
    "ax1.set_title(\"Optimization Progress\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: sampled points\n",
    "x1_vals = [obs.inputs[\"x1\"] for obs in all_obs]\n",
    "x2_vals = [obs.inputs[\"x2\"] for obs in all_obs]\n",
    "sc = ax2.scatter(x1_vals, x2_vals, c=range(len(all_obs)), cmap=\"viridis\", s=60)\n",
    "ax2.scatter([TRUE_OPTIMUM[\"x1\"]], [TRUE_OPTIMUM[\"x2\"]], c=\"red\", marker=\"*\", s=200, label=\"True optimum\")\n",
    "ax2.set_xlabel(\"x1\")\n",
    "ax2.set_ylabel(\"x2\")\n",
    "ax2.set_title(\"Sampled Points\")\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.set_ylim(0, 10)\n",
    "ax2.legend()\n",
    "plt.colorbar(sc, ax=ax2, label=\"Iteration\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Error Handling with `stop_on_error`\n",
    "\n",
    "The `execute()` method supports graceful error handling. If an experiment fails,\n",
    "you can choose to:\n",
    "- `stop_on_error=True` (default): Stop immediately and raise the error\n",
    "- `stop_on_error=False`: Log the error and continue with remaining iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlakyExecutor(Executor):\n",
    "    \"\"\"An executor that occasionally fails (for demo purposes).\"\"\"\n",
    "    \n",
    "    def __init__(self, func, fail_prob: float = 0.3):\n",
    "        self.func = func\n",
    "        self.fail_prob = fail_prob\n",
    "    \n",
    "    def _run(self, suggestion: dict, project: Project) -> Observation:\n",
    "        if np.random.random() < self.fail_prob:\n",
    "            raise RuntimeError(\"Simulated equipment failure!\")\n",
    "        \n",
    "        outputs = self.func(**suggestion)\n",
    "        return Observation(\n",
    "            project_id=project.id,\n",
    "            inputs=suggestion,\n",
    "            outputs=outputs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project for flaky executor demo\n",
    "folio.create_project(\n",
    "    name=\"flaky_demo\",\n",
    "    inputs=[\n",
    "        InputSpec(\"x1\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "        InputSpec(\"x2\", \"continuous\", bounds=(0.0, 10.0)),\n",
    "    ],\n",
    "    outputs=[OutputSpec(\"yield\")],\n",
    "    target_configs=[TargetConfig(objective=\"yield\", objective_mode=\"maximize\")],\n",
    ")\n",
    "\n",
    "flaky_executor = FlakyExecutor(branin_like, fail_prob=0.3)\n",
    "\n",
    "# Run with stop_on_error=False to continue despite failures\n",
    "np.random.seed(42)  # For reproducibility\n",
    "obs_list = folio.execute(\n",
    "    project_name=\"flaky_demo\",\n",
    "    n_iter=10,\n",
    "    stop_on_error=False,  # Continue despite errors\n",
    "    executor=flaky_executor,\n",
    ")\n",
    "\n",
    "print(f\"Attempted 10 experiments, {len(obs_list)} succeeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Using `wait_between_runs`\n",
    "\n",
    "For rate-limited APIs or experiments that need cooldown time, use `wait_between_runs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create another project\n",
    "folio.create_project(\n",
    "    name=\"wait_demo\",\n",
    "    inputs=[InputSpec(\"x\", \"continuous\", bounds=(0.0, 10.0))],\n",
    "    outputs=[OutputSpec(\"y\")],\n",
    "    target_configs=[TargetConfig(objective=\"y\", objective_mode=\"maximize\")],\n",
    ")\n",
    "\n",
    "def simple_func(x):\n",
    "    return {\"y\": -(x - 5)**2 + 25}\n",
    "\n",
    "simple_executor = SimulatorExecutor(simple_func)\n",
    "\n",
    "start_time = time.time()\n",
    "folio.execute(\n",
    "    project_name=\"wait_demo\",\n",
    "    n_iter=3,\n",
    "    wait_between_runs=0.5,  # Wait 0.5 seconds between runs\n",
    "    executor=simple_executor,\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"3 iterations with 0.5s wait took {elapsed:.2f}s (expected ~1.5s of wait time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Built-in Executors\n",
    "\n",
    "Folio provides two built-in executors:\n",
    "\n",
    "### HumanExecutor\n",
    "Prompts a human to run experiments manually and enter results:\n",
    "```python\n",
    "from folio.executors import HumanExecutor\n",
    "\n",
    "executor = HumanExecutor()\n",
    "# When execute() is called, user is prompted:\n",
    "#   \"Suggested inputs: {'temperature': 80.0}\"\n",
    "#   \"Enter actual temperature: \"\n",
    "#   \"Enter yield: \"\n",
    "#   \"Did experiment fail? [y/n]: \"\n",
    "```\n",
    "\n",
    "### ClaudeLightExecutor\n",
    "Calls the Claude-Light API for fully autonomous experiments:\n",
    "```python\n",
    "from folio.executors import ClaudeLightExecutor\n",
    "\n",
    "executor = ClaudeLightExecutor(api_url=\"https://claude-light.cheme.cmu.edu/api\")\n",
    "# Sends RGB values to API, receives measured values back\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Using `build_executor()` for Quick Setup\n",
    "\n",
    "For built-in executors, you can use `folio.build_executor()` to instantiate and cache them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and cache a HumanExecutor\n",
    "human_executor = folio.build_executor(\"human\")\n",
    "print(f\"Built executor: {type(human_executor).__name__}\")\n",
    "print(f\"Cached in folio.executor: {folio.executor is human_executor}\")\n",
    "\n",
    "# Switch to ClaudeLightExecutor\n",
    "claude_executor = folio.build_executor(\"claude_light\")\n",
    "print(f\"\\nSwitched to: {type(claude_executor).__name__}\")\n",
    "print(f\"Cached executor updated: {folio.executor is claude_executor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## HumanExecutor Demo\n",
    "\n",
    "The `HumanExecutor` prompts users to enter actual input values and output measurements\n",
    "via the command line. This is useful for manual experiments where you need to record\n",
    "what was actually done (which may differ from the suggestion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a project for human executor demo\n",
    "folio.create_project(\n",
    "    name=\"human_demo\",\n",
    "    inputs=[\n",
    "        InputSpec(\"temperature\", \"continuous\", bounds=(50.0, 150.0)),\n",
    "        InputSpec(\"pressure\", \"continuous\", bounds=(1.0, 10.0)),\n",
    "    ],\n",
    "    outputs=[OutputSpec(\"yield\")],\n",
    "    target_configs=[TargetConfig(objective=\"yield\", objective_mode=\"maximize\")],\n",
    ")\n",
    "\n",
    "# Run one iteration with HumanExecutor\n",
    "# You will be prompted to enter:\n",
    "#   1. Actual temperature (what you really set)\n",
    "#   2. Actual pressure (what you really set)\n",
    "#   3. The measured yield\n",
    "#   4. Whether the experiment failed\n",
    "#   5. Any notes\n",
    "#   6. A tag (optional)\n",
    "human_executor = HumanExecutor()\n",
    "obs_list = folio.execute(\n",
    "    project_name=\"human_demo\",\n",
    "    n_iter=1,\n",
    "    executor=human_executor,\n",
    ")\n",
    "\n",
    "print(f\"\\nRecorded observation:\")\n",
    "print(f\"  Inputs: {obs_list[0].inputs}\")\n",
    "print(f\"  Outputs: {obs_list[0].outputs}\")\n",
    "print(f\"  Failed: {obs_list[0].failed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Executors enable **automated closed-loop optimization** in Folio:\n",
    "\n",
    "1. **Create custom executors** by subclassing `Executor` and implementing `_run()`\n",
    "2. **Use `folio.execute()`** to automate the suggest → execute → record loop\n",
    "3. **Handle errors gracefully** with `stop_on_error=False`\n",
    "4. **Control pacing** with `wait_between_runs`\n",
    "5. **Use built-in executors** for human-in-the-loop or Claude-Light integration\n",
    "\n",
    "This pattern makes it easy to:\n",
    "- Test optimization strategies with simulators\n",
    "- Deploy to real experiments with minimal code changes\n",
    "- Run fully autonomous optimization campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "folio.delete_project(\"executor_demo\")\n",
    "folio.delete_project(\"flaky_demo\")\n",
    "folio.delete_project(\"wait_demo\")\n",
    "folio.delete_project(\"human_demo\")\n",
    "print(\"Demo complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "folio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
